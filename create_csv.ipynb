{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e41dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample_78_features.csv with 78 features and all attack types.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler to get the correct feature names\n",
    "scaler = joblib.load(\"models/scaler.pkl\")\n",
    "feature_names = list(scaler.feature_names_in_)  # 78 features\n",
    "\n",
    "# Example class names (edit as needed)\n",
    "class_names = [\n",
    "    \"BENIGN\",\"Bot\",\"DDoS\",\"DoS GoldenEye\",\"DoS Hulk\",\"DoS Slowhttptest\",\"DoS slowloris\",\n",
    "    \"FTP-Patator\",\"Heartbleed\",\"Infiltration\",\"PortScan\",\"SSH-Patator\",\n",
    "    \"Web Attack � Brute Force\",\"Web Attack � Sql Injection\",\"Web Attack � XSS\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "n_rows = 15  # One for each class\n",
    "for i, label in enumerate(class_names):\n",
    "    row = list(np.random.uniform(0, 30, len(feature_names)))\n",
    "    row.append(label)\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=feature_names + ['label'])\n",
    "df.to_csv(\"sample_78_features.csv\", index=False)\n",
    "print(\"Created sample_78_features.csv with 78 features and all attack types.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf646a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 rows to 'random_rows_combined.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "input_folder = 'data'  # Change this to your folder path\n",
    "output_file = 'random_rows_combined.csv'\n",
    "rows_per_file = 10  # Number of random rows to select from each file\n",
    "\n",
    "# Collect all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(input_folder) if file.endswith('.csv')]\n",
    "\n",
    "# List to store sampled DataFrames\n",
    "sampled_rows = []\n",
    "\n",
    "# Process each file\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        sample_count = min(rows_per_file, len(df))  # In case file has fewer rows\n",
    "        sampled_df = df.sample(n=sample_count, random_state=42)  # Random but reproducible\n",
    "        sampled_df['source_file'] = file_name  # Optional: to know where each row came from\n",
    "        sampled_rows.append(sampled_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "# Combine all sampled rows\n",
    "if sampled_rows:\n",
    "    result_df = pd.concat(sampled_rows, ignore_index=True)\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(result_df)} rows to '{output_file}'\")\n",
    "else:\n",
    "    print(\"No rows sampled from any file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3144a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "df = pd.read_csv('data/Wednesday-workingHours.pcap_ISCX.csv')\n",
    "\n",
    "# Sample 1000 rows\n",
    "sampled_df = df.sample(n=100, random_state=42)\n",
    "\n",
    "# Save to new file\n",
    "sampled_df.to_csv('Wednesday-workingHours_sampled2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1d77bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1000 rows from Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Sampled 1000 rows from Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Sampled 1000 rows from Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Sampled 1000 rows from Monday-WorkingHours.pcap_ISCX.csv\n",
      "Sampled 1000 rows from Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "Sampled 1000 rows from Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "Sampled 1000 rows from Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Sampled 1000 rows from Wednesday-workingHours.pcap_ISCX.csv\n",
      "\n",
      "Saved combined sampled data to Output/combined_sampled_2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "input_folder = 'data'  # Folder containing the CSV files\n",
    "output_file = 'Output/combined_sampled_2.csv'  # Final output file\n",
    "sample_size = 1000  # Number of random rows to select from each file\n",
    "random_seed = 42  # For reproducibility\n",
    "\n",
    "# Make sure output folder exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# List to collect sampled data\n",
    "all_samples = []\n",
    "\n",
    "# Process each file\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # If file has fewer rows than the sample size, use all rows\n",
    "        n = min(sample_size, len(df))\n",
    "        sampled_df = df.sample(n=n, random_state=random_seed)\n",
    "\n",
    "        # Optional: Add filename as a column for traceability\n",
    "        sampled_df['source_file'] = filename\n",
    "\n",
    "        all_samples.append(sampled_df)\n",
    "\n",
    "        print(f\"Sampled {n} rows from {filename}\")\n",
    "\n",
    "# Combine all samples and save to one file\n",
    "combined_df = pd.concat(all_samples, ignore_index=True)\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nSaved combined sampled data to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
